\documentclass{article}

\usepackage{minted}
\usepackage[hyphens]{url}
\usepackage{microtype}
\usepackage{hyperref}
\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan
}

\begin{document}

\title{Creating a Stand-Alone Spark Environment in Windows Subsystem for Linux}
\author{Abraham Vargas}
\maketitle

\newpage
\tableofcontents
\newpage

\section{\emph{Windows Subsystem for Linux}}
\emph{Windows Subsystem for Linux} (\emph{WSL}) allows \emph{Linux} a distribution (distro) to
run concurrently with \emph{Windows 10}. \emph{WSL 2} now includes a \emph{Linux}
kernel and is several times faster than the original \emph{WSL}. This guide assumes that \emph{WSL 2}
is installed and is running the \emph{Ubuntu 18.04} distro. To install \emph{WSL 2}, follow the
\href{https://docs.microsoft.com/en-us/windows/wsl/install-win10}{Windows Subsystem for Linux Installation Guide for Windows 10}.
Make sure to use \emph{Ubuntu 18.04} as the distro.

\section{Java}
\emph{Spark}, \emph{Hadoop}, and \emph{Hive} all require a \emph{Java Runtime Environment}(\emph{JRE}).
\emph{OpenJDK} is a standard package in most \emph{Linux} distributions. Though \emph{OpenJDK 11}
is the latest version, \emph{Spark} and its related components require \emph{OpenJDK 8}.

    \subsection{Install \emph{JRE}}
    To install \emph{OpenJDK 8}, run the following command in a terminal:
    \begin{minted}{bash}
        sudo apt install openjdk-8-jre-headless openjdk-8-jdk-headless  
    \end{minted}

    \subsection{Set \emph{JAVA\_HOME}}
    \label{sec:javahome}
    \emph{Spark} and other components will need to know the path of the
    \emph{JRE}. This is accomplished by setting the \emph{JAVA\_HOME}
    system variable.

    \begin{description}
        \item[Open] the \emph{.bashrc} file with any editor (e.g., \emph{vim}, \emph{nano}).
        For example:
        \begin{minted}{bash}
            vim ~/.bashrc
        \end{minted}

        \item[Add] the following line to the \emph{.bashrc} file:
        \begin{minted}{bash}
            export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64                 
        \end{minted}
        
        \item[Reload] shell environment configuration:
        \begin{minted}{bash}
            source ~/.bashrc
        \end{minted}

        \item[Verify] that path was correctly set:
        \begin{minted}{bash}
            echo $JAVA_HOME
        \end{minted}
    \end{description}

\section{\emph{PostgreSQL}}
\label{sec:postgres}
\emph{Hive} requires a database for its metastore. In terms of open-source options, \emph{Hive} can use
\emph{MySQL}, \emph{PostgreSQL}, and \emph{Derby}. This guide will use \emph{PostgreSQL}.

    \subsection{Install \emph{PostgreSQL}}
    \emph{PostgreSQL 10} is the default version packaged for \emph{Ubuntu 18.04}. Install
    \emph{PostgreSQL 10} with the command:
    \begin{minted}{bash}
        sudo apt install postgresql-10
    \end{minted}

    \subsection{Start database server}
    The \emph{PostgreSQL} will need to be started every time \emph{WSL} is started. Initialize the
    server using the command:
    \begin{minted}{bash}
        sudo service postgresql start
    \end{minted}

    \subsection{Configure \emph{Hive} metastore}
    The \emph{psql} application is used to interact with \emph{PostgreSQL} in a terminal.
    \begin{description}
        \item[Log into] \emph{PostgreSQL} via \emph{psql} with default user \emph{postgres}:
        \begin{minted}{bash}
            sudo -u postgres psql 
        \end{minted}

        \item[Add] new user \emph{hive}
        (for simplicity, the new user will also be given \emph{hive} as the password):
        \begin{minted}{postgres}
            CREATE USER hive WITH PASSWORD 'hive';
        \end{minted}

        \item[Create] new database for \emph{Hive} metastore:
        \begin{minted}{postgres}
            CREATE DATABASE hive_metastore;
        \end{minted}

        \item[Give] ownership of \emph{hive\_metastore} database to user \emph{hive}:
        \begin{minted}{postgres}
            ALTER DATABASE hive_metastore OWNER TO hive;
        \end{minted}

        \item[Exit] \emph{psql} with the command: \mintinline{psql}{\q}
    \end{description}

    \subsection{Install \emph{Java Database Connectivity} Drivers}
    The \emph{Java Database Connectivity} (\emph{JDBC}) drivers allow \emph{Java} to interact with
    databases. As \emph{Hive} runs in \emph{Java}, it requires the \emph{PostgreSQL JDBC} drivers.
    Install the drivers drivers in \emph{Ubuntu} via the following command:
    \begin{minted}{bash}
        sudo apt install libpostgresql-jdbc-java
    \end{minted}

\section{SSH Key}
\emph{Secure Shell} (\emph{SSH}) encrypts communications over insecure networks. To accomplish encryption
\emph{SSH} utilizes public and private keys.

    \subsection{Generate key}
     Generate] an \emph{ssh key} with the following command:
        \begin{minted}{bash}
            ssh-keygen -t rsa
        \end{minted}
    Leave the password blank when prompted, as \emph{Hadoop} will utilize a password-less \emph{ssh}
    login.

    \subsection{Allow \emph{localhost} login}
    \emph{Hadoop} requires the ability to log into the \emph{localhost} (i.e., your local PC) via
    password-less \emph{ssh}. To accomplish this, run the following command:
    \begin{minted}{bash}
        cat ~/.ssh/id_rsa.pub >> ~/.ssh/authorized_keys
    \end{minted}

    \subsection{Restart \emph{ssh} service}
    \label{subsec:sshrestart}
    Run the following command to apply new settings:
    \begin{minted}{bash}
        sudo service ssh restart
    \end{minted}
    This command must be re-executed any time the following error message is encountered:
    \begin{minted}{bash}
        ssh: connect to host localhost port 22: Connection refused
    \end{minted}

    \subsection{Verify password-less \emph{ssh} login}
    Ensure that \emph{localhost} can be accessed via \emph{ssh} without a password:
    \begin{minted}{bash}
        ssh localhost
    \end{minted}
    If an error message is returned, restart the \emph{ssh} service (section \ref{subsec:sshrestart}).

\section{\emph{Hadoop}}
\emph{Apache Hadoop} is a framework that is used to store and process \emph{big data} in distributed systems.
In this guide, \emph{Hadoop} will be used as a data storage system on a single PC.

    \subsection{Download and extract \emph{Hadoop 3.3.0}}
    This guide will use the latest stable version, \emph{Hadoop 3.3.0}.
    
        \subsubsection{Download \emph{Hadoop}}
        Run the \emph{wget} command in a terminal to download:
        \begin{minted}{bash}
            wget https://apache.osuosl.org/hadoop/common/hadoop-3.3.0/hadoop-3.3.0.tar.gz
        \end{minted}

        \subsubsection{Extract files}
        Run the following command in a terminal to extract the \emph{tar.gz} file:
        \begin{minted}{bash}
            tar -xvzf hadoop-3.3.0.tar.gz
        \end{minted}
        A new directory, \path{hadoop-3.3.0}, should now appear.

        \subsubsection{Copy folder to \emph{/opt}}
        In \emph{Ubuntu}, \path{/opt} is the directory used to store add-on applications. \emph{Hadoop},
        \emph{Hive}, and \emph{Spark} will all be stored in this directory. Run the following command to
        move the extracted \emph{Hive} folder:
        \begin{minted}{bash}
            sudo mv hadoop-3.3.0 /opt
        \end{minted}
    
    \subsection{Set \emph{HADOOP\_HOME}}
    Setting the \emph{HADOOP\_HOME} variable tells the system where \emph{HADOOP} is located.

        \subsubsection{Edit \emph{.bashrc}}
        \label{subsec:hadoophome}
        Open the \emph{$\sim$/.bashrc} file and add the following line:
        \begin{minted}{bash}
            export HADOOP_HOME=/opt/hadoop-3.3.0
        \end{minted}

        \subsubsection{Reload configuration}
        \label{subsec:reloadbash}
        Load the new \emph{bash} configuration with the command:
        \begin{minted}{bash}
            source ~/.bashrc
        \end{minted}

        \subsubsection{Verify path}
        Verify that \emph{HADOOP\_HOME} was correctly set:
        \begin{minted}{bash}
            echo $HADOOP_HOME
        \end{minted}
        The path should match that in \ref{subsec:hadoophome}.
    
    \subsection{Add \emph{Hadoop} to system path}
    In order to run \emph{Hadoop} commands without having to specify a full path, e.g.,
    \begin{minted}{bash}
        /opt/hadoop-3.3.0/bin/hadoop fs -mkdir /tmp
    \end{minted}
    vs.
    \begin{minted}{bash}
        hadoop fs -mkdir /tmp
    \end{minted}
    add the following line to $\sim$/.bashrc:
    \begin{minted}{bash}
        export PATH=$PATH:$HADOOP_HOME/bin
    \end{minted}
    Make sure to reload the \emph{Bash} configuration as in section \ref{subsec:reloadbash}.

    \subsection{Edit configuration files}
    In this section, \emph{Hadoop} will be configured to run in single-node mode (i.e., on a single PC).

        % This section might not be needed if setting JAVA_HOME in .bashrc is enough
        \subsubsection{Edit \emph{hadoop-env.sh}}
        Add the \emph{JAVA\_HOME} variable to the \emph{Hadoop} environment, as in section \ref{sec:javahome}.

        \begin{enumerate}
            \item Open the file \path{/opt/hadoop-3.3.0/etc/hadoop/hadoop-env.sh} with any editor
            
            \item Un-comment line \emph{54} and add the correct path:
            \begin{minted}{bash}
                # The java implementation to use. By default, this environment
                # variable is REQUIRED on ALL platforms except OS X!
                export JAVA_HOME=/usr/lib/jvm/java-8-openjdk-amd64
            \end{minted}
        \end{enumerate}

        \subsubsection{Edit \emph{core-site.xml}}
        Edit the file \path{/opt/hadoop-3.3.0/etc/hadoop/core-site.xml} to look like the example below:
        \begin{minted}{xml}
            <configuration>
                <property>
                    <name>fs.defaultFS</name>
                    <value>hdfs://localhost:9000</value>
                </property>
                <property>
                    <name>hadoop.proxyuser.abe.hosts</name>
                    <value>*</value>
                </property>
                <property>
                    <name>hadoop.proxyuser.abe.groups</name>
                    <value>*</value>
                </property>
            </configuration>
        \end{minted}
        Replace \emph{abe} above with your own \emph{WSL} system username.

        \subsubsection{Edit \emph{hdfs-site.xml}}
        Edit the file \path{/opt/hadoop-3.3.0/etc/hadoop/hdfs-site.xml} to look like the example below:
        \begin{minted}{xml}
            <configuration>
                <property>
                    <name>dfs.replication</name>
                    <value>1</value>
                </property>
            </configuration>
        \end{minted}
        
        \subsubsection{Edit \emph{mapred-site.xml}}
        Edit the file \path{/opt/hadoop-3.3.0/etc/hadoop/mapred-site.xml} to look like the example below:
        % Verify that splitting the <value> into two lines works
        \begin{minted}{xml}
            <configuration>
                <property>
                    <name>mapreduce.framework.name</name>
                    <value>yarn</value>
                </property>
                <property>
                    <name>mapreduce.application.classpath</name>
                    <value>
                        $HADOOP_MAPRED_HOME/share/hadoop/mapreduce/*:
                        $HADOOP_MAPRED_HOME/share/hadoop/mapreduce/lib/*
                    </value>
                </property>
            </configuration>
        \end{minted}
        
        \subsubsection{Edit \emph{yarn-site.xml}}
        Edit the file \path{/opt/hadoop-3.3.0/etc/hadoop/yarn-site.xml} to look like the example below:
        % Verify that splitting the <value> into two lines works
        \begin{minted}{xml}
            <configuration>
                <property>
                    <name>yarn.nodemanager.aux-services</name>
                    <value>mapreduce_shuffle</value>
                </property>
                <property>
                    <name>yarn.nodemanager.env-whitelist</name>
                    <value>
                        JAVA_HOME,HADOOP_COMMON_HOME,HADOOP_HDFS_HOME,
                        HADOOP_CONF_DIR,CLASSPATH_PREPEND_DISTCACHE,
                        HADOOP_YARN_HOME,HADOOP_MAPRED_HOME
                    </value>
                </property>
            </configuration>
        \end{minted}

    \subsection{Format \emph{HDFS}}
    Format the \emph{Hadoop Distributed File System} (\emph{HDFS}) with the command:
    \begin{minted}{bash}
        /opt/hadoop-3.3.0/bin/hdfs namenode -format
    \end{minted}
    The \emph{hdfs} command will output several lines of \emph{INFO} messages.

    \subsection{Start \emph{NameNode} and \emph{DataNode} daemons}
    The daemons allow a web interface containing \emph{Hadoop} system stats to run. To start both
    daemons, run the command:
    \begin{minted}{bash}
        /opt/hadoop-3.3.0/sbin/start-dfs.sh
    \end{minted}
    The above command might return a \emph{connection refused} error. If this occurs, restart
    the \emph{ssh} service (see section \ref{subsec:sshrestart}). The web interface should now be
    accessible via \url{http://localhost:9870/}.

    \subsection{Start \emph{YARN} daemon}
    \emph{YARN} acts as a resource manager in a \emph{Hadoop} system. To start the \emph{YARN} daemon,
    run the command:
    \begin{minted}{bash}
        /opt/hadoop-3.3.0/sbin/start-yarn.sh
    \end{minted}
    The resource manager web interface should now be accessible via
    \url{http://localhost:8088/}.

\section{Hive}
\emph{Apache Hive} is a data warehousing application that utilizes \emph{SQL} to interact with
data residing in distributed systems. \emph{Hive} requires a metastore service, which in this case
is provided by \emph{PostgreSQL} (section \ref{sec:postgres}).

    \subsection{Download and extract \emph{Hive}}
    This guide will use the current latest stable version, \emph{Apache Hive 3.1.2}.
    \begin{enumerate}
        \item Download \emph{Hive} via the \emph{wget} terminal command:
        \begin{minted}[autogobble]{bash}
            wget http://apache.mirrors.pair.com/hive/hive-3.1.2/apache-hive-3.1.2-bin.tar.gz
        \end{minted}

        \item Unpack \emph{Hive} file using the \emph{tar} command:
        \begin{minted}{bash}
            tar -xvzf apache-hive-3.1.2-bin.tar.gz
        \end{minted}

        \item Move new folder to /opt directory:
        \begin{minted}{bash}
            sudo mv apache-hive-3.1.2-bin /opt
        \end{minted}
    \end{enumerate}

    \subsection{Set \emph{HIVE\_HOME}}
    The \emph{HIVE\_HOME} variable must be set in order to let the system know its location.
    \begin{enumerate}
        \item Open $\sim$/.bashrc with an editor, as in the example below:
        \begin{minted}{bash}
            vim ~/.bashrc
        \end{minted}

        \item Add the following line to the \emph{.bashrc} file:
        \label{itm:hivehome}
        \begin{minted}{bash}
            export HIVE_HOME=/opt/apache-hive-3.1.2-bin
        \end{minted}

        \item Reload \emph{Bash} terminal configuration:
        \begin{minted}{bash}
            source ~/.bashrc
        \end{minted}
        
        \item Ensure \emph{HIVE\_HOME} path has been correctly set:
        \begin{minted}{bash}
            echo $HIVE_HOME
        \end{minted}
        Output should contain the path configured in step \ref{itm:hivehome} above.
    \end{enumerate}

    \subsection{Initialize all \emph{Hadoop} services}
    As \emph{Hive} manages data in a \emph{Hadoop} system, the latter must be running.
    Run the following command in a terminal to start all \emph{Hadoop} services:
    \begin{minted}{bash}
        $HADOOP_HOME/sbin/start-all.sh
    \end{minted}
    If the above command returns \emph{connection refused} errors, restart \emph{ssh} service as
    in section \ref{subsec:sshrestart}.

    \subsection{Configure \emph{HDFS}}
    The \emph{HDFS} directories that \emph{Hive} will use must first be created and configured.
    Run the following commands to create the required \emph{Hive} folders and assign appropriate
    permissions:

    \begin{minted}{bash}
        hadoop fs -mkdir /tmp 
        hadoop fs -mkdir -p /user/hive/warehouse 
        hadoop fs -chmod g+w /tmp 
        hadoop fs -chmod g+w /user/hive/warehouse
    \end{minted}

    \subsection{Edit \emph{hive-site.xml}}
    The \emph{hive-site.xml} file contains required configuration settings for the \emph{Hive} metastore.
    In this setup, the metastore resides within a \emph{PostgreSQL} database (see section \ref{sec:postgres}).

        \subsubsection{Create file}
        Copy file \emph{hive-default.xml.template} and rename it as \emph{hive-site.xml}:
        \begin{minted}{bash}
            cd /opt/apache-hive-3.1.2-bin/conf
            cp hive-default.xml.template hive-site.xml
        \end{minted}

        \subsubsection{Prevent \emph{URISyntaxException}}
        To prevent a \emph{Java URISyntaxException} from being returned when attempting to run \emph{Hive}
        services (see section \ref{subsec:hiveservices}), add the following lines to the beginning of
        \emph{hive-site.xml}:
        \begin{minted}{xml}
            <property>
                <name>system:java.io.tmpdir</name>
                <value>/tmp/hive/java</value>
            </property>
            <property>
                <name>system:user.name</name>
                <value>${user.name}</value>
            </property>
        \end{minted}

        \subsubsection{Edit configuration settings}
        Edit the following values in the \emph{hive-site.xml} file at the lines shown below:
        \begin{minted}[numbers=left, firstnumber=461]{xml}
            <name>hive.metastore.uris</name>
            <value>thrift://127.0.0.1:9083</value>
        \end{minted}
        \centerline{\vdots}
        \begin{minted}[numbers=left, firstnumber=568]{xml}
            <name>javax.jdo.option.ConnectionPassword</name>
            <value>hive</value>
        \end{minted}
        \centerline{\vdots}
        \begin{minted}[numbers=left, firstnumber=583]{xml}
            <name>javax.jdo.option.ConnectionURL</name>
            <value>jdbc:postgresql://127.0.0.1/hive_metastore</value>
        \end{minted}
        \centerline{\vdots}
        \begin{minted}[numbers=left, firstnumber=1101]{xml}
            <name>javax.jdo.option.ConnectionDriverName</name>
            <value>org.postgresql.Driver</value>
        \end{minted}
        \centerline{\vdots}
        \begin{minted}[numbers=left, firstnumber=1126]{xml}
            <name>javax.jdo.option.ConnectionUserName</name>
            <value>hive</value>
        \end{minted}

        \subsubsection{Remove illegal characters}
        Line 3215 in \emph{hive-site.xml} contains illegal characters that will cause a
        \emph{Java RuntimeException} in step \ref{subsec:schematool}. Remove the characters highlighted below from line 3215:
        \begin{minted}[autogobble, escapeinside=||]{xml}
            <property>
                <name>hive.txn.xlock.iow</name>
                <value>true</value>
                <description>|\dots|acquire Exclusive locks for|\colorbox{yellow}{&#8}||\dots|INSERT OVERWRITE.</description>
            </property>
        \end{minted}

    \subsection{Update \emph{guava} version}
    The versions of \emph{guava} between \emph{Hadoop 3.3.0} and \emph{Hive 3.1.2} are not compatible.
    Having different versions will result in a \emph{Java NoSuchMethodError} in step \ref{subsec:schematool}.
    \begin{enumerate}
        \item Delete \emph{guava 19.0} from \emph{Hive}:
        \begin{minted}{bash}
            cd /opt/apache-hive-3.1.2-bin
            rm lib/guava-19.0.jar
        \end{minted}

        \item Replace with \emph{guava 27.0} included with \emph{Hadoop}:
        \begin{minted}[autogobble]{bash}
            cp /opt/hadoop-3.3.0/share/hadoop/hdfs/lib/guava-27.0-jre.jar lib/
        \end{minted}
    \end{enumerate}

    \subsection{Create \emph{PostgreSQL} database structure}
    \label{subsec:schematool}
    The command below will create the database structure for the \emph{Hive} metastore. Once
    successfully completed, the output should conclude with the message \emph{schemaTool completed}.
    \begin{minted}{bash}
        /opt/apache-hive-3.1.2-bin/bin/schematool -dbType postgres -initSchema
    \end{minted}

    \subsection{Start \emph{Hive} services}
    \label{subsec:hiveservices}
    In order to use \emph{Hive}, its metastore service must be started. \emph{Hive} also provides
    a web interface with information on running sessions, queries, etc.

        \subsubsection{Initialize \emph{Hive} metastore service}
        Run the following command in a terminal to start \emph{Hive} metastore services:
        \begin{minted}{bash}
            $HIVE_HOME/bin/hive --service metastore
        \end{minted}

        \subsubsection{Initialize \emph{Hive} server}
        Open another terminal and run the following command to Initialize the \emph{Hive} server:
        \begin{minted}{bash}
            $HIVE_HOME/bin/hive --service hiveserver2
        \end{minted}

        \subsubsection{Access web interface}
        After about one minute of running both metastore and \emph{Hive} server, access the web
        interface via \url{http://localhost:10002/}

\newpage
\begin{thebibliography}{9}
    \bibitem{postgres_metastore}
    Hewlett Packard Enterprise Development LP,
    \textit{Configuring a Remote PostgreSQL Database for the Hive Metastore},
    2020,
    \url{https://docs.datafabric.hpe.com/61/Hive/Config-RemotePostgreSQLForHiveMetastore.html}
    
    \bibitem{hadoop_install}
    The Apache Software Foundation,
    \textit{Hadoop: Setting up a Single Node Cluster},
    2020,
    \url{https://hadoop.apache.org/docs/r3.3.0/hadoop-project-dist/hadoop-common/SingleCluster.html}

    \bibitem{ubuntu_install}
    Debian Installer Team,
    \textit{Ubuntu Installation Guide},
    2020,
    \url{https://help.ubuntu.com/lts/installation-guide/amd64/index.html}

    \bibitem{guava_error}
    Pradeep Kumar, Javi Roman,
    \textit{Hive Issue 22915},
    2020,
    \url{https://issues.apache.org/jira/browse/HIVE-22915}

    \bibitem{hive}
    Raymond Tang,
    \textit{Apache Hive 3.1.1 Installation on Windows 10 using Windows Subsystem for Linux},
    2018,
    \url{https://kontext.tech/column/hadoop/309/apache-hive-311-installation-on-windows-10-using-windows-subsystem-for-linux}

    \bibitem{hive_error_fix}
    Vu Duc Tiep,
    \textit{[Hive Installation] java.net.URISyntaxException: Relative path in absolute URI},
    2017,
    \url{http://driftingengineer.blogspot.com/2017/09/hive-installation-javaneturisyntaxexcep.html}
\end{thebibliography}

\end{document}